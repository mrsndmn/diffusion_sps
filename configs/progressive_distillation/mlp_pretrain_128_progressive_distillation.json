{
    "experiment_name": "mlp_pretrain_128_progressive_distillation",
    "nn_model_type": "mlp",
    "hidden_layers": 3,
    "dataset": "dino",
    "train_batch_size": 200,
    "eval_batch_size": 1000,
    "num_epochs": 100,
    "learning_rate": 0.0001,
    "num_timesteps": 128,
    "beta_schedule": "linear",
    "embedding_size": 128,
    "hidden_size": 128,
    "time_embedding": "sinusoidal",
    "input_embedding": "sinusoidal",
    "save_images_step": 25,
    "device": "cpu",
    "sps_checkpoint": null,

    "distillation_steps": 1,
    "distillation_factor": 2,
    "teacher_checkpoint": "exps/mlp/model.pth",
    "student_scheduler_beta_correction": false
}