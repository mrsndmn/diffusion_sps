{
    "experiment_name": "mlp_pretrain_128",
    "nn_model_type": "mlp",
    "hidden_layers": 1,
    "embedding_size": 64,
    "hidden_size": 128,
    "num_timesteps": 128,

    "dataset": "dino",
    "train_batch_size": 200,
    "eval_batch_size": 1000,
    "num_epochs": 100,
    "sps_checkpoint": null,
    "learning_rate": 0.001,
    "beta_schedule": "linear",
    "time_embedding": "sinusoidal",
    "input_embedding": "sinusoidal",
    "save_images_step": 25,
    "device": "cpu"
}