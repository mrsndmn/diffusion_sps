{
    "experiment_name": "progressive_distillation_multistage_big",
    "nn_model_type": "mlp",
    "hidden_layers": 6,
    "embedding_size": 256,
    "hidden_size": 256,
    "dataset": "dino",
    "train_batch_size": 200,
    "eval_batch_size": 1000,
    "num_epochs": 50,
    "learning_rate": 0.001,
    "num_timesteps": 128,
    "beta_schedule": "linear",
    "time_embedding": "sinusoidal",
    "input_embedding": "sinusoidal",
    "save_images_step": 10,
    "device": "cpu",
    "sps_checkpoint": null,

    "distillation_steps": 5,
    "teacher_checkpoint": "exps/mlp_pretrain_128_big/model.pth",
    "student_scheduler_beta_correction": true
}